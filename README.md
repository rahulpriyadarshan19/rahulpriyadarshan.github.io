### Education

M.Sc Astronomy and Data Science, Leiden University  
B.Tech Aerospace Engineering, Indian Institute of Technology Madras  


### Research Projects

#### **Emulating a photodissociation region (PDR) code with deep learning (2nd master's thesis)**

In this work, I developed and trained a deep learning architecture based on Neural Ordinary Differential Equations (NeuralODE) to mimic/emulate the performance of an astrochemical modelling code, `3DPDR`. The network evaluates chemistry in photodissociation regions (PDR) about ~17000 times faster, and produces accurate predictions for many chemical species and temperatures. For more details, click here.

![Predicted vs true abundances](./assets/model_565_pred_abundances.png "Predicted vs true abundances")

![Abundances of different chemical species](./assets/species_plot.png "Abundances of different chemical species")

#### **Interstellar Broadening with LOFAR (1st master's thesis)**
In this work, I measured the interstellar scattering effect that causes poorer resolution (broadening) of astronomical images at radio frequencies. I  found that broadening reduces with increasing radio frequencies, as expected. For more details, click here. 

![Scattering width versus frequency](./assets/scattering_UM_updated_1.png "Scattering width versus frequency")

### Course projects

#### **Acrobot: Policy-based Reinforcement Learning**
In this project, my team and I implemented the REINFORCE and different variants of the Actor-Critic policy-based RL algorithms. We evaluate their performance using the Acrobot environment in Gymnasium. We found that actor-critic in combination with bootstrapping and baseline subtraction provides a high mean reward compared to REINFORCE or plain vanilla Actor-Critic, as expected. 

![Performance of Actor-Critic](./assets/peformance_bootstrapping_baseline_subtraction.jpg "Performance of Actor-Critic with Bootstrapping and Baseline Subtraction")

#### **Cartpole: Value-based Reinforcement Learning**
In this project, my team and I implemented variants of Q-Learning, an off-policy value-based RL algorithm, and evaluated its performance on the Cartpole environment in Gymnasium. We found that the DQN algorithm, i.e. Q-Learning implemented with a replay buffer and a target network performs best, as expected.

![Performance of DQN](./assets/DQN_performance.png "Performance of DQN")

#### **CAntenna: An L-Band paint can interferometer**

#### **Betelgeuse's expanding Oort cloud: an interstellar threat?**















## Outreach